Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6589943952858448	0.9186585247516632	0.6640625	0.14583333333333331
2	0.4951343722641468	1.2977367639541626	0.728515625	0.14583333333333331
3	0.37351152673363686	1.1605709791183472	0.82421875	0.14583333333333331
4	0.2782065374776721	0.41860757768154144	0.86328125	0.7916666666666667
5	0.19214819325134158	0.45288635790348053	0.919921875	0.859375
6	0.12441323511302471	0.37187568843364716	0.96875	0.8229166666666667
7	0.08484866470098495	0.3865012228488922	0.98046875	0.8489583333333333
8	0.05789586738683283	0.6819794625043869	0.99609375	0.921875
9	0.037874986534006894	0.4111448749899864	0.998046875	0.9427083333333333
10	0.02887552697211504	0.4197831228375435	0.998046875	0.9270833333333333
11	0.02270765375578776	0.39680200815200806	1.0	0.9270833333333333
12	0.019567225128412247	0.384751059114933	0.998046875	0.90625
13	0.021469843457452953	0.563753217458725	0.99609375	0.9635416666666667
14	0.01705615344690159	0.6869480311870575	1.0	0.9427083333333333
15	0.017075885640224442	0.39814266562461853	0.998046875	0.9427083333333333
16	0.013908907334553078	0.529316321015358	0.99609375	0.9427083333333333
17	0.009429305442608893	0.5197428539395332	1.0	0.9427083333333333
18	0.006778537092031911	0.5215923860669136	1.0	0.9427083333333333
19	0.005438640102511272	0.4853486940264702	1.0	0.9427083333333333
20	0.004051440642797388	0.5115643665194511	1.0	0.9427083333333333
21	0.003691667807288468	0.5198315680027008	1.0	0.9427083333333333
22	0.0032507374926353805	0.5155019536614418	1.0	0.9427083333333333
23	0.0029434684620355256	0.5006068795919418	1.0	0.9427083333333333
24	0.002586481816251762	0.5071559026837349	1.0	0.9427083333333333
25	0.0023524669813923538	0.5546791031956673	1.0	0.9427083333333333
26	0.0023745678408886306	0.5487103685736656	1.0	0.9427083333333333
27	0.002301014304975979	0.5328049212694168	1.0	0.9427083333333333
28	0.001900265422591474	0.522841289639473	1.0	0.9427083333333333
29	0.0017747658203006722	0.5519163459539413	1.0	0.9427083333333333
30	0.0019343224485055543	0.5461060106754303	1.0	0.9427083333333333
31	0.0016109932766994461	0.5454695522785187	1.0	0.9427083333333333
32	0.0015279947510862257	0.5520486459136009	1.0	0.9427083333333333
33	0.0015939059376250952	0.5469885021448135	1.0	0.9427083333333333
34	0.001594659210240934	0.5642249062657356	1.0	0.9427083333333333
35	0.0015373646892840043	0.5480499416589737	1.0	0.9427083333333333
36	0.001297989238082664	0.5360724553465843	1.0	0.9427083333333333
37	0.0013864697684766725	0.5682380944490433	1.0	0.9427083333333333
38	0.0014063784328754991	0.5741816535592079	1.0	0.9427083333333333
39	0.0012367825547698885	0.5542736500501633	1.0	0.9427083333333333
40	0.001124633570725564	0.5616710409522057	1.0	0.9427083333333333
41	0.0011703271011356264	0.5737975239753723	1.0	0.9427083333333333
42	0.0010477594732947182	0.5652453377842903	1.0	0.9427083333333333
43	0.0010233111861452926	0.5711953192949295	1.0	0.9427083333333333
44	0.0009694245272839908	0.5816177129745483	1.0	0.9427083333333333
45	0.0009988473066186998	0.6004154309630394	1.0	0.9427083333333333
46	0.0008590966335759731	0.6038640290498734	1.0	0.9427083333333333
47	0.0008600839973951224	0.593685045838356	1.0	0.9427083333333333
48	0.0008429578429058893	0.585088424384594	1.0	0.9427083333333333
49	0.0008211085842049215	0.586640864610672	1.0	0.9427083333333333
50	0.0008119676949718269	0.5781198740005493	1.0	0.9427083333333333

Chosen model = epoch number 6


Train data : Accu-0.94921875	Loss-0.17114538187161088
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.9435294 0.9709443       425
     class 1  0.7473684 1.0000000 0.8554217        71

    accuracy                      0.9516129       496
   macro avg  0.8736842 0.9717647 0.9131830       496
weighted avg  0.9638370 0.9516129 0.9544078       496








Valid data : Accu-0.8229166666666667	Loss-0.37187568843364716
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9756098 0.8333333 0.8988764        48
     class 1  0.4666667 0.8750000 0.6086957         8

    accuracy                      0.8392857        56
   macro avg  0.7211382 0.8541667 0.7537860        56
weighted avg  0.9029036 0.8392857 0.8574220        56








Test data : Accu-0.853125	Loss-0.3681609183549881
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9375000 0.8823529 0.9090909        51
     class 1  0.5714286 0.7272727 0.6400000        11

    accuracy                      0.8548387        62
   macro avg  0.7544643 0.8048128 0.7745455        62
weighted avg  0.8725518 0.8548387 0.8613490        62





