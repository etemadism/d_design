Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6099780313670635	0.7907193899154663	0.66015625	0.14583333333333331
2	0.44548392854630947	0.9425320625305176	0.73046875	0.14583333333333331
3	0.31999075785279274	0.7968471646308899	0.84765625	0.14583333333333331
4	0.22481758845970035	0.3654940575361252	0.916015625	0.8072916666666667
5	0.14667679811827838	0.38895268738269806	0.953125	0.796875
6	0.09602208528667688	0.347907155752182	0.97265625	0.8020833333333333
7	0.06316223461180925	0.40561266243457794	0.986328125	0.9322916666666667
8	0.03919435292482376	0.41319483518600464	0.998046875	0.9322916666666667
9	0.040140537603292614	0.5069541782140732	0.99609375	0.9479166666666667
10	0.051518239080905914	0.39869358390569687	0.9921875	0.9427083333333333
11	0.04122641176218167	0.5429112017154694	0.990234375	0.90625
12	0.029875250882469118	0.31891781091690063	0.994140625	0.8333333333333333
13	0.021381109778303653	0.46627695113420486	0.994140625	0.9479166666666667
14	0.011683371238177642	0.3890959471464157	0.998046875	0.90625
15	0.008806317375274375	0.42088397592306137	1.0	0.90625
16	0.006621139531489462	0.4736403599381447	1.0	0.9114583333333333
17	0.004742577628348954	0.48986832052469254	1.0	0.9114583333333333
18	0.004059071856318042	0.4863288700580597	1.0	0.9114583333333333
19	0.0036056805547559634	0.49104709923267365	1.0	0.9114583333333333
20	0.003332342705107294	0.5103859528899193	1.0	0.9270833333333333
21	0.0030448236284428276	0.515859380364418	1.0	0.9270833333333333
22	0.0033005374862113968	0.5136623159050941	1.0	0.9270833333333333
23	0.0026052207831526175	0.5146944299340248	1.0	0.9270833333333333
24	0.0022999947104835883	0.5214346796274185	1.0	0.9270833333333333
25	0.0021984933118801564	0.5251149535179138	1.0	0.9270833333333333
26	0.002138179261237383	0.5431441441178322	1.0	0.9270833333333333
27	0.0019810024969046935	0.5352622047066689	1.0	0.9270833333333333
28	0.0018540901437518187	0.5359246209263802	1.0	0.9270833333333333
29	0.0016855145986482967	0.5461826175451279	1.0	0.9270833333333333
30	0.001571833712660009	0.5524999499320984	1.0	0.9270833333333333
31	0.0015171103841566946	0.548419639468193	1.0	0.9270833333333333
32	0.001353281426418107	0.556966058909893	1.0	0.9270833333333333
33	0.0012560164323076606	0.5688943639397621	1.0	0.9270833333333333
34	0.0013081900906399824	0.5653264671564102	1.0	0.9270833333333333
35	0.001193757649161853	0.5717841535806656	1.0	0.9270833333333333
36	0.0012553133128676564	0.5903329402208328	1.0	0.9114583333333333
37	0.001239846198586747	0.5942126587033272	1.0	0.9270833333333333
38	0.0011730107107723597	0.5979184657335281	1.0	0.9270833333333333
39	0.0009786202772374963	0.5998717099428177	1.0	0.9270833333333333
40	0.000990347944025416	0.5944864451885223	1.0	0.9270833333333333
41	0.0009849114212556742	0.5984855741262436	1.0	0.9270833333333333
42	0.0010304261049896013	0.6054929941892624	1.0	0.9270833333333333
43	0.0009146438533207402	0.5979010686278343	1.0	0.9270833333333333
44	0.0008614260987087619	0.5997594743967056	1.0	0.9270833333333333
45	0.0008893683225323912	0.6192726269364357	1.0	0.9114583333333333
46	0.0007722391983406851	0.6202626451849937	1.0	0.9270833333333333
47	0.0008032498699321877	0.6325016543269157	1.0	0.9270833333333333
48	0.0008031239594856743	0.6313884183764458	1.0	0.9114583333333333
49	0.0008129218294925522	0.6277507022023201	1.0	0.9114583333333333
50	0.000759248514441424	0.6437617838382721	1.0	0.9114583333333333

Chosen model = epoch number 12


Train data : Accu-0.984375	Loss-0.06095988815650344
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.9811765 0.9904988       425
     class 1  0.8987342 1.0000000 0.9466667        71

    accuracy                      0.9838710       496
   macro avg  0.9493671 0.9905882 0.9685827       496
weighted avg  0.9855043 0.9838710 0.9842245       496








Valid data : Accu-0.8333333333333333	Loss-0.31891781091690063
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9756098 0.8333333 0.8988764        48
     class 1  0.4666667 0.8750000 0.6086957         8

    accuracy                      0.8392857        56
   macro avg  0.7211382 0.8541667 0.7537860        56
weighted avg  0.9029036 0.8392857 0.8574220        56








Test data : Accu-0.8885416666666667	Loss-0.39466550946235657
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9230769 0.9411765 0.9320388        51
     class 1  0.7000000 0.6363636 0.6666667        11

    accuracy                      0.8870968        62
   macro avg  0.8115385 0.7887701 0.7993528        62
weighted avg  0.8834988 0.8870968 0.8849567        62





