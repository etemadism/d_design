Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6652749180793762	0.7252158224582672	0.587890625	0.140625
2	0.5003767944872379	0.8377125561237335	0.759765625	0.140625
3	0.3953364063054323	0.6355639398097992	0.82421875	0.203125
4	0.27681125048547983	0.4724330008029938	0.876953125	0.7708333333333333
5	0.21298632258549333	0.5544048547744751	0.93359375	0.890625
6	0.14779975172132254	0.36743731796741486	0.962890625	0.84375
7	0.1051657295320183	0.49071142077445984	0.98828125	0.9427083333333333
8	0.06828408758156002	0.33266572654247284	0.9921875	0.8072916666666667
9	0.058704466093331575	0.3308228999376297	0.9921875	0.8333333333333333
10	0.048711249022744596	0.5843811333179474	0.994140625	0.9270833333333333
11	0.058065625140443444	0.3130652457475662	0.984375	0.8541666666666667
12	0.05176784854847938	0.3290821611881256	0.994140625	0.9479166666666667
13	0.049849508330225945	0.5203452259302139	0.990234375	0.96875
14	0.05525720166042447	0.40363645553588867	0.984375	0.8645833333333333
15	0.14025653223507106	1.0121338665485382	0.95703125	0.9114583333333333
16	0.12006283574737608	1.4201124906539917	0.94921875	0.8697916666666667
17	0.10043127415701747	1.3363787531852722	0.97265625	0.8541666666666667
18	0.07693908864166588	0.4924989491701126	0.98046875	0.7239583333333333
19	0.04211932996986434	0.3954422026872635	0.98828125	0.8489583333333333
20	0.018483195133740082	0.34550756216049194	0.998046875	0.8854166666666667
21	0.010926444680080749	0.3739193081855774	1.0	0.921875
22	0.008470976972603239	0.3739703744649887	1.0	0.921875
23	0.006902675639139488	0.37479957938194275	1.0	0.921875
24	0.006360865183523856	0.3919850140810013	1.0	0.921875
25	0.005347706079191994	0.38480909168720245	1.0	0.921875
26	0.0046102904379949905	0.3842584490776062	1.0	0.921875
27	0.0046982533822301775	0.38349561393260956	1.0	0.921875
28	0.004054915894812439	0.39279574155807495	1.0	0.921875
29	0.003776346471568104	0.40312688052654266	1.0	0.921875
30	0.003646083569037728	0.4086991250514984	1.0	0.921875
31	0.0029769808970740996	0.4109441936016083	1.0	0.921875
32	0.0030961477204982657	0.3945683389902115	1.0	0.921875
33	0.0029222832163213752	0.39840951561927795	1.0	0.921875
34	0.002491985804226715	0.402349516749382	1.0	0.921875
35	0.0026759947650134563	0.40530820190906525	1.0	0.921875
36	0.0023629903298569843	0.41055987775325775	1.0	0.921875
37	0.002150165539205773	0.4168807417154312	1.0	0.921875
38	0.002156831498723477	0.41491255164146423	1.0	0.921875
39	0.0020211529481457546	0.41680487990379333	1.0	0.921875
40	0.0018364589523116592	0.4165561720728874	1.0	0.921875
41	0.0016892420171643607	0.4149407222867012	1.0	0.921875
42	0.0016108129457279574	0.41995614767074585	1.0	0.921875
43	0.0016166790555871557	0.41714847832918167	1.0	0.921875
44	0.0015087321971805068	0.4185136556625366	1.0	0.921875
45	0.0015304973858292215	0.42417047917842865	1.0	0.921875
46	0.0013969046922284178	0.4319913387298584	1.0	0.921875
47	0.0014026412773091579	0.4330626353621483	1.0	0.921875
48	0.001391374691593228	0.4262581765651703	1.0	0.921875
49	0.001299843435845105	0.425784133374691	1.0	0.921875
50	0.0013666006980201928	0.4303695783019066	1.0	0.921875

Chosen model = epoch number 11


Train data : Accu-0.91015625	Loss-0.14520201878622174
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.8917647 0.9427861       425
     class 1  0.6068376 1.0000000 0.7553191        71

    accuracy                      0.9072581       496
   macro avg  0.8034188 0.9458824 0.8490526       496
weighted avg  0.9437207 0.9072581 0.9159511       496








Valid data : Accu-0.8541666666666667	Loss-0.3130652457475662
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9761905 0.8541667 0.9111111        48
     class 1  0.5000000 0.8750000 0.6363636         8

    accuracy                      0.8571429        56
   macro avg  0.7380952 0.8645833 0.7737374        56
weighted avg  0.9081633 0.8571429 0.8718615        56








Test data : Accu-0.8072916666666667	Loss-0.49968305230140686
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9333333 0.8235294 0.8750000        51
     class 1  0.4705882 0.7272727 0.5714286        11

    accuracy                      0.8064516        62
   macro avg  0.7019608 0.7754011 0.7232143        62
weighted avg  0.8512334 0.8064516 0.8211406        62





