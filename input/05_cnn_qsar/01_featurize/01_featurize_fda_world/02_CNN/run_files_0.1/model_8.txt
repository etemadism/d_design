Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6298752166330814	0.7772818803787231	0.69140625	0.140625
2	0.4539143368601799	0.9627943634986877	0.75	0.140625
3	0.3516601286828518	0.9697501957416534	0.84765625	0.140625
4	0.24511720426380634	0.4164828062057495	0.908203125	0.8697916666666667
5	0.1619694740511477	0.3837294653058052	0.958984375	0.8697916666666667
6	0.12430645432323217	0.5643980950117111	0.970703125	0.90625
7	0.09705253294669092	0.5011201351881027	0.98046875	0.75
8	0.09578768978826702	0.5675758570432663	0.98046875	0.9375
9	0.06069996673613787	0.5181566067039967	0.98828125	0.8645833333333333
10	0.037417730840388685	0.5187882967293262	0.99609375	0.8802083333333333
11	0.03391171008115634	0.4551759511232376	0.998046875	0.9010416666666667
12	0.02772177691804245	0.7675832062959671	1.0	0.8697916666666667
13	0.026070153224281967	0.39268049597740173	0.998046875	0.84375
14	0.020771556883119047	0.6207779981195927	1.0	0.9010416666666667
15	0.023238347988808528	0.3965001441538334	0.99609375	0.9427083333333333
16	0.023893258650787175	0.9778891578316689	0.99609375	0.921875
17	0.018797885859385133	0.6481072157621384	1.0	0.8697916666666667
18	0.01677202378050424	0.7404760383069515	0.998046875	0.9010416666666667
19	0.014012927858857438	0.8641700726002455	1.0	0.9010416666666667
20	0.008774666217505	0.8790394775569439	1.0	0.921875
21	0.006999945675488561	0.7154102027416229	1.0	0.921875
22	0.005768600836745463	0.8404123988002539	1.0	0.8802083333333333
23	0.004341961437603459	0.7107583470642567	1.0	0.9010416666666667
24	0.004324089146393817	0.6977962125092745	1.0	0.9010416666666667
25	0.004742982651805505	0.6587609723210335	1.0	0.859375
26	0.004905240042717196	0.9051889395341277	1.0	0.9010416666666667
27	0.0068679618707392365	0.7080458924174309	1.0	0.859375
28	0.006598604275495745	1.2488604448735714	1.0	0.921875
29	0.006604161673749331	0.8830464966595173	1.0	0.8802083333333333
30	0.00941208956646733	1.2478002905845642	1.0	0.9166666666666667
31	0.0077292064524954185	0.8874517045915127	1.0	0.921875
32	0.004900688261841424	0.8720750771462917	1.0	0.921875
33	0.003426989263971336	0.7488734610378742	1.0	0.9010416666666667
34	0.0028758409098372795	0.6327368766069412	1.0	0.9010416666666667
35	0.0022638090413238388	0.8234398188069463	1.0	0.9010416666666667
36	0.0019781867922574747	0.8783259708434343	1.0	0.9010416666666667
37	0.001947857021150412	0.8013417329639196	1.0	0.9010416666666667
38	0.001759360748110339	0.782578008249402	1.0	0.9010416666666667
39	0.0015075892697495874	0.8498241472989321	1.0	0.9010416666666667
40	0.0014695704994664993	0.8363629914820194	1.0	0.9010416666666667
41	0.0014105384889262496	0.8616251405328512	1.0	0.9010416666666667
42	0.0011988345904683229	0.9302153270691633	1.0	0.9010416666666667
43	0.001751191695802845	0.9844764033332467	1.0	0.9010416666666667
44	0.0015459916248801164	1.0536690382286906	1.0	0.9166666666666667
45	0.0012519040465122089	0.9708735467866063	1.0	0.9010416666666667
46	0.0011014059564331546	0.9219079101458192	1.0	0.9010416666666667
47	0.0010494864654901903	0.9100344739854336	1.0	0.9010416666666667
48	0.001003312934699352	0.9146609343588352	1.0	0.9010416666666667
49	0.0010103885197167983	0.89142095297575	1.0	0.9010416666666667
50	0.0009530530569463735	0.9494045088067651	1.0	0.9010416666666667

Chosen model = epoch number 5


Train data : Accu-0.947265625	Loss-0.16300787450745702
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.9364706 0.9671932       425
     class 1  0.7244898 1.0000000 0.8402367        71

    accuracy                      0.9455645       496
   macro avg  0.8622449 0.9682353 0.9037149       496
weighted avg  0.9605620 0.9455645 0.9490200       496








Valid data : Accu-0.8697916666666667	Loss-0.3837294653058052
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9767442 0.8750000 0.9230769        48
     class 1  0.5384615 0.8750000 0.6666667         8

    accuracy                      0.8750000        56
   macro avg  0.7576029 0.8750000 0.7948718        56
weighted avg  0.9141324 0.8750000 0.8864469        56








Test data : Accu-0.85625	Loss-0.3709782809019089
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9565217 0.8627451 0.9072165        51
     class 1  0.5625000 0.8181818 0.6666667        11

    accuracy                      0.8548387        62
   macro avg  0.7595109 0.8404635 0.7869416        62
weighted avg  0.8866147 0.8548387 0.8645383        62





