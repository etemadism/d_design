Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6481286939233541	0.7250204086303711	0.48828125	0.14583333333333331
2	0.5069496482610703	0.7043023407459259	0.744140625	0.14583333333333331
3	0.3764946572482586	0.4867773801088333	0.853515625	0.78125
4	0.27492325101047754	0.3783864825963974	0.900390625	0.90625
5	0.19026730535551906	0.41688837110996246	0.947265625	0.90625
6	0.13925254624336958	0.5247589945793152	0.96875	0.9270833333333333
7	0.1556459297426045	0.3680032938718796	0.9609375	0.8177083333333333
8	0.1265683954115957	0.3331339806318283	0.97265625	0.9635416666666667
9	0.09611801477149129	0.43431149423122406	0.978515625	0.8541666666666667
10	0.07773528748657554	0.5468470528721809	0.982421875	0.9270833333333333
11	0.059619557461701334	0.5436629056930542	0.990234375	0.9114583333333333
12	0.04412535211304203	0.5479273051023483	0.994140625	0.9427083333333333
13	0.04167792375665158	0.4916904643177986	0.9921875	0.9270833333333333
14	0.03462836297694594	0.659225732088089	0.99609375	0.9427083333333333
15	0.03349916741717607	0.34490570798516273	0.998046875	0.9427083333333333
16	0.023359992017503828	0.3967660814523697	1.0	0.90625
17	0.01432031751028262	0.3346222937107086	1.0	0.9427083333333333
18	0.01171492385037709	0.3699887953698635	1.0	0.9427083333333333
19	0.008598304892075248	0.3976566195487976	1.0	0.9427083333333333
20	0.007213315038825385	0.42745089903473854	1.0	0.9427083333333333
21	0.006970594025915489	0.42664091289043427	1.0	0.9427083333333333
22	0.00656895678548608	0.4252079054713249	1.0	0.9427083333333333
23	0.005860942997969687	0.43801309168338776	1.0	0.9427083333333333
24	0.005888570398383308	0.43977412208914757	1.0	0.9427083333333333
25	0.004398363962536678	0.45197126269340515	1.0	0.9427083333333333
26	0.004155157374043483	0.47173559851944447	1.0	0.9427083333333333
27	0.003993528094724752	0.48972994461655617	1.0	0.9427083333333333
28	0.0034464039854356088	0.4879387766122818	1.0	0.9427083333333333
29	0.0035933947656303644	0.47439679503440857	1.0	0.9427083333333333
30	0.0036322059604572132	0.4739250112324953	1.0	0.9427083333333333
31	0.002985243198054377	0.4705013185739517	1.0	0.9427083333333333
32	0.0028838141879532486	0.4669169969856739	1.0	0.9427083333333333
33	0.003148816482280381	0.4842461347579956	1.0	0.9427083333333333
34	0.003101349764619954	0.4904998354613781	1.0	0.9427083333333333
35	0.0026885105471592396	0.49727291986346245	1.0	0.9427083333333333
36	0.0029102153384883422	0.4705832190811634	1.0	0.9427083333333333
37	0.0028914937756781	0.47680653631687164	1.0	0.9427083333333333
38	0.002570898192061577	0.4968967121094465	1.0	0.9427083333333333
39	0.0022547366097569466	0.46884044259786606	1.0	0.9427083333333333
40	0.00206642204648233	0.47347698360681534	1.0	0.9427083333333333
41	0.0019117194424325135	0.480032904073596	1.0	0.9427083333333333
42	0.0018066871562041342	0.5020136125385761	1.0	0.9427083333333333
43	0.0017133481051132549	0.5032231472432613	1.0	0.9427083333333333
44	0.001615368586499244	0.501474317163229	1.0	0.9427083333333333
45	0.0016135983969434164	0.5106667187064886	1.0	0.9427083333333333
46	0.001889552117063431	0.5228457823395729	1.0	0.9427083333333333
47	0.0014737269702891354	0.5274727866053581	1.0	0.9427083333333333
48	0.001555046415887773	0.5260749161243439	1.0	0.9427083333333333
49	0.0013204416809458053	0.5384652428328991	1.0	0.9427083333333333
50	0.0011765009639930213	0.5454399678856134	1.0	0.9427083333333333

Chosen model = epoch number 8


Train data : Accu-0.998046875	Loss-0.04803087713662535
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.9976471 0.9988221       425
     class 1  0.9861111 1.0000000 0.9930070        71

    accuracy                      0.9979839       496
   macro avg  0.9930556 0.9988235 0.9959146       496
weighted avg  0.9980119 0.9979839 0.9979897       496








Valid data : Accu-0.9635416666666667	Loss-0.3331339806318283
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9791667 0.9791667 0.9791667        48
     class 1  0.8750000 0.8750000 0.8750000         8

    accuracy                      0.9642857        56
   macro avg  0.9270833 0.9270833 0.9270833        56
weighted avg  0.9642857 0.9642857 0.9642857        56








Test data : Accu-0.91875	Loss-0.754177063703537
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9107143 1.0000000 0.9532710        51
     class 1  1.0000000 0.5454545 0.7058824        11

    accuracy                      0.9193548        62
   macro avg  0.9553571 0.7727273 0.8295767        62
weighted avg  0.9265553 0.9193548 0.9093795        62





