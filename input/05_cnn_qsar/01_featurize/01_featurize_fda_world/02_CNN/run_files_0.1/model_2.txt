Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {1: 71, 0: 425}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.5957898013293743	1.8880798816680908	0.7109375	0.13541666666666666
2	0.43431428633630276	2.304733633995056	0.798828125	0.13541666666666666
3	0.3499489026144147	1.6171513199806213	0.84765625	0.13541666666666666
4	0.24147230945527554	0.6126505136489868	0.919921875	0.609375
5	0.1692829141393304	0.5581727027893066	0.958984375	0.7447916666666667
6	0.09865205083042383	0.5418882519006729	0.984375	0.734375
7	0.06091432739049196	0.5022376850247383	0.994140625	0.9635416666666667
8	0.04171962116379291	0.5009986460208893	0.998046875	0.9270833333333333
9	0.02824353869073093	0.4929756075143814	1.0	0.8177083333333333
10	0.019602893036790192	0.49262838810682297	1.0	0.90625
11	0.016262359509710222	0.5520714893937111	1.0	0.90625
12	0.014624314586399123	0.6049922481179237	1.0	0.8958333333333333
13	0.011870617629028857	0.47535666450858116	1.0	0.9270833333333333
14	0.011076735041569918	0.6591762751340866	1.0	0.9635416666666667
15	0.009958458715118468	0.5364306718111038	1.0	0.9479166666666667
16	0.012928534400998615	0.834383562207222	1.0	0.9635416666666667
17	0.014458868507063016	0.5453551784157753	1.0	0.8541666666666667
18	0.012393605255056173	1.4522279798984528	1.0	0.9010416666666667
19	0.0143662563059479	0.7498381286859512	0.998046875	0.9635416666666667
20	0.043498223763890564	1.173068881034851	0.986328125	0.9479166666666667
21	0.07963823270983994	0.9226002246141434	0.974609375	0.8020833333333333
22	0.19858832680620253	3.8210569620132446	0.93359375	0.8489583333333333
23	0.25191877130419016	1.9515616297721863	0.90625	0.8958333333333333
24	0.08828481833916157	0.7390839755535126	0.955078125	0.90625
25	0.037664188945200294	0.9515027403831482	0.984375	0.9270833333333333
26	0.03568425093544647	0.5418623834848404	0.990234375	0.875
27	0.015610875881975517	0.6944950670003891	1.0	0.875
28	0.008938421407947317	0.7653559669852257	1.0	0.875
29	0.006105449181632139	0.8024563863873482	1.0	0.8958333333333333
30	0.004936654964694753	0.8284834623336792	1.0	0.8958333333333333
31	0.004049941329867579	0.8496012687683105	1.0	0.875
32	0.00360212849045638	0.8572967946529388	1.0	0.875
33	0.003619410199462436	0.8860345408320427	1.0	0.875
34	0.0029107649534125812	0.8970748633146286	1.0	0.875
35	0.0024605571743450128	0.9045082405209541	1.0	0.875
36	0.002472208325343672	0.9130178615450859	1.0	0.875
37	0.00216404625098221	0.923397459089756	1.0	0.875
38	0.002071482675091829	0.9241902753710747	1.0	0.875
39	0.002124615781212924	0.9349316731095314	1.0	0.875
40	0.0019460070616332814	0.9414979070425034	1.0	0.875
41	0.001830016673920909	0.9413184523582458	1.0	0.875
42	0.001768475089193089	0.9530588462948799	1.0	0.890625
43	0.001422013810952194	0.9525206983089447	1.0	0.875
44	0.0012820576048397925	0.9584665149450302	1.0	0.875
45	0.0014444504959101323	0.9687439948320389	1.0	0.875
46	0.0012648727170017082	0.9752219989895821	1.0	0.875
47	0.0013633692724397406	0.9784366860985756	1.0	0.875
48	0.0012596617416420486	0.9842436984181404	1.0	0.875
49	0.001235310857737204	0.9867159873247147	1.0	0.875
50	0.0012140782091591973	1.0014810264110565	1.0	0.875

Chosen model = epoch number 13


Train data : Accu-1.0	Loss-0.01656757073942572
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 1.0000000 1.0000000       425
     class 1  1.0000000 1.0000000 1.0000000        71

    accuracy                      1.0000000       496
   macro avg  1.0000000 1.0000000 1.0000000       496
weighted avg  1.0000000 1.0000000 1.0000000       496








Valid data : Accu-0.9270833333333333	Loss-0.47535666450858116
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9782609 0.9375000 0.9574468        48
     class 1  0.7000000 0.8750000 0.7777778         8

    accuracy                      0.9285714        56
   macro avg  0.8391304 0.9062500 0.8676123        56
weighted avg  0.9385093 0.9285714 0.9317798        56








Test data : Accu-0.8875	Loss-0.9101783335208893
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9230769 0.9411765 0.9320388        51
     class 1  0.7000000 0.6363636 0.6666667        11

    accuracy                      0.8870968        62
   macro avg  0.8115385 0.7887701 0.7993528        62
weighted avg  0.8834988 0.8870968 0.8849567        62





