Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6328553147614002	1.1554738581180573	0.654296875	0.15625
2	0.4694729167968035	1.412122517824173	0.77734375	0.15625
3	0.3472247226163745	1.172820895910263	0.8515625	0.15625
4	0.2518395846709609	0.43293115496635437	0.90625	0.7864583333333333
5	0.1753014475107193	0.3622249513864517	0.955078125	0.8697916666666667
6	0.11149198841303587	0.38427025079727173	0.974609375	0.84375
7	0.07957056141458452	0.38147755712270737	0.984375	0.875
8	0.0552619966911152	0.3116272762417793	0.9921875	0.9270833333333333
9	0.041677808621898293	0.29021283239126205	0.998046875	0.9114583333333333
10	0.03754338144790381	0.33424606919288635	0.994140625	0.8958333333333333
11	0.03253716218750924	0.4023856520652771	0.998046875	0.9583333333333333
12	0.02732934249797836	0.4683254063129425	1.0	0.8854166666666667
13	0.023742440505884588	0.35330940037965775	0.998046875	0.890625
14	0.01615772192599252	0.3439403846859932	1.0	0.9427083333333333
15	0.0134207830124069	0.3448599576950073	1.0	0.890625
16	0.012405633606249467	0.34809838235378265	0.99609375	0.890625
17	0.01817126598325558	0.37880323827266693	1.0	0.890625
18	0.015774765226524323	0.3640938997268677	1.0	0.9114583333333333
19	0.009162724556517787	0.4552166759967804	1.0	0.921875
20	0.006696587966871448	0.3951399624347687	1.0	0.9114583333333333
21	0.004931763214699458	0.40833571553230286	1.0	0.9114583333333333
22	0.004183769546216354	0.4090278074145317	1.0	0.9114583333333333
23	0.0035336413275217637	0.4286242127418518	1.0	0.9114583333333333
24	0.0033128563591162674	0.4068804979324341	1.0	0.875
25	0.0029871145598008297	0.4255751967430115	1.0	0.9114583333333333
26	0.0026562666607787833	0.4422525502741337	1.0	0.9427083333333333
27	0.0028405818666215055	0.4537638798356056	1.0	0.8958333333333333
28	0.002327261507161893	0.4575257748365402	1.0	0.9270833333333333
29	0.0021250969839456957	0.454755999147892	1.0	0.9427083333333333
30	0.002349248534301296	0.4636956974864006	1.0	0.9270833333333333
31	0.0018031958061328623	0.4692004844546318	1.0	0.9114583333333333
32	0.0018571711480035447	0.4758705198764801	1.0	0.90625
33	0.0017566192982485518	0.48012765496969223	1.0	0.890625
34	0.0015824996080482379	0.4924604445695877	1.0	0.90625
35	0.0014570512030331884	0.5039357766509056	1.0	0.9270833333333333
36	0.0015123390076041687	0.5071699246764183	1.0	0.921875
37	0.001601101626874879	0.5066471844911575	1.0	0.9427083333333333
38	0.0014159563834255096	0.5179088562726974	1.0	0.90625
39	0.0013515818864107132	0.5259496420621872	1.0	0.9270833333333333
40	0.0015708022765466012	0.5226849466562271	1.0	0.9270833333333333
41	0.0023530048492830247	0.5247748792171478	1.0	0.9270833333333333
42	0.0032170499216590542	0.5094190314412117	1.0	0.875
43	0.004367571291368222	0.449754498898983	1.0	0.8958333333333333
44	0.005458095834910637	0.639975018799305	1.0	0.90625
45	0.004733010933705373	0.5175893604755402	1.0	0.9270833333333333
46	0.005947250923782121	0.3746500611305237	1.0	0.9635416666666667
47	0.0042185916026937775	0.4449149779975414	1.0	0.9270833333333333
48	0.00341597060469212	0.4590362161397934	1.0	0.90625
49	0.0026052705907204654	0.4856405183672905	1.0	0.9114583333333333
50	0.001797934528440237	0.4734139256179333	1.0	0.9270833333333333

Chosen model = epoch number 9


Train data : Accu-0.998046875	Loss-0.024853990820702165
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.9976471 0.9988221       425
     class 1  0.9861111 1.0000000 0.9930070        71

    accuracy                      0.9979839       496
   macro avg  0.9930556 0.9988235 0.9959146       496
weighted avg  0.9980119 0.9979839 0.9979897       496








Valid data : Accu-0.9114583333333333	Loss-0.29021283239126205
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9777778 0.9166667 0.9462366        48
     class 1  0.6363636 0.8750000 0.7368421         8

    accuracy                      0.9107143        56
   macro avg  0.8070707 0.8958333 0.8415393        56
weighted avg  0.9290043 0.9107143 0.9163231        56








Test data : Accu-0.9197916666666667	Loss-0.4618948623538017
Test data report 
-              precision    recall  f1-score   support

     class 0  0.9423077 0.9607843 0.9514563        51
     class 1  0.8000000 0.7272727 0.7619048        11

    accuracy                      0.9193548        62
   macro avg  0.8711538 0.8440285 0.8566805        62
weighted avg  0.9170596 0.9193548 0.9178262        62





