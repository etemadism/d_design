input_file_train = ../01_split/data/data_splits/CV_train_0.1.txt
input_file_test = ../01_split/data/data_splits/CV_test_0.1.txt
trial = False
k_fold_value = 10
run_folder = run_files_0.1
gpu_id = 0
sequence_length_cutoff = {'lensize': '42', 'atomsize': '400'}
conv1 = {'_comments': 'k=window size,s=strides,f=number of filters', 'k1': '11', 's1': '1', 'f1': '128'}
pool1 = {'k2': '5', 's2': '1'}
conv2 = {'k3': '11', 's3': '1', 'f3': '64'}
pool2 = {'k4': '5', 's4': '1'}
fc_layer_parameters = {'n_hid': '96'}
network_parameters = {'optimizer': 'adam', 'batchsize': '32', 'epochs': '50', 'learning_rate': '1e-3', 'enable_class_weight': True}
Used atomsize 400
model = Net(
  (conv1): Conv2d(1, 128, kernel_size=(11, 42), stride=(1, 1), padding=(5, 0))
  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (leakyr): LeakyReLU(negative_slope=0.01)
  (pool1): AvgPool2d(kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
  (conv2): Conv2d(128, 64, kernel_size=(11, 1), stride=(1, 1), padding=(5, 0))
  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (pool2): AvgPool2d(kernel_size=(5, 1), stride=(1, 1), padding=(2, 0))
  (fc1): Linear(in_features=64, out_features=96, bias=True)
  (fc2): Linear(in_features=96, out_features=2, bias=True)
  (bn3): BatchNorm1d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dropout): Dropout(p=0.2, inplace=False)
)
