Class weight for loss (balancing weights) = tensor([0.1671, 1.0000])
Training : Class distribution = {0: 425, 1: 71}
Valid : Class distribution = {0: 48, 1: 8}
Test : Class distribution = {0: 51, 1: 11}
Epochs = 50
Learning rate = 0.001
optimizer = Adam
criterion = CrossEntropyLoss
Epoch	LOSStrain	LOSSval	ACCUtrain	ACCUval
1	0.6131867822259665	1.0618510842323303	0.603515625	0.14583333333333331
2	0.4373558759689331	1.12596994638443	0.775390625	0.14583333333333331
3	0.3130026599392295	0.7146623134613037	0.8359375	0.14583333333333331
4	0.23169582802802324	0.5279479622840881	0.90625	0.47395833333333337
5	0.16481513599865139	0.42855145037174225	0.955078125	0.8697916666666667
6	0.1064504727255553	0.3304605931043625	0.982421875	0.8489583333333333
7	0.06525725848041475	0.37170813977718353	0.98828125	0.890625
8	0.05283940420486033	0.30202658474445343	0.990234375	0.9270833333333333
9	0.037616210465785116	0.3165830969810486	0.99609375	0.8854166666666667
10	0.024998280016006902	0.38545965403318405	0.998046875	0.9270833333333333
11	0.021160945325391367	0.36006346344947815	0.998046875	0.90625
12	0.01575336276437156	0.37530244141817093	1.0	0.9270833333333333
13	0.012207396619487554	0.41470668464899063	1.0	0.9114583333333333
14	0.009823897111346014	0.4250388890504837	1.0	0.9427083333333333
15	0.008030305296415463	0.3795297294855118	1.0	0.8854166666666667
16	0.006457600145949982	0.40091966837644577	1.0	0.9010416666666667
17	0.005293181951856241	0.427371621131897	1.0	0.921875
18	0.0046118516474962234	0.4159165658056736	1.0	0.90625
19	0.004296893734135665	0.40039393305778503	1.0	0.921875
20	0.003810930415056646	0.4377279058098793	1.0	0.921875
21	0.003529624365910422	0.4424265883862972	1.0	0.921875
22	0.003254150979046244	0.4573182836174965	1.0	0.921875
23	0.003000611897732597	0.4483678266406059	1.0	0.921875
24	0.0028568003835971467	0.4286935552954674	1.0	0.921875
25	0.002583104716904927	0.44163884222507477	1.0	0.921875
26	0.0022910184670763556	0.46591605246067047	1.0	0.921875
27	0.0021129383603692986	0.46171311289072037	1.0	0.921875
28	0.0021369812384364195	0.46755078434944153	1.0	0.921875
29	0.0020230698137311265	0.46262574195861816	1.0	0.921875
30	0.001883591390651418	0.4710529148578644	1.0	0.921875
31	0.001774784606823232	0.46996769681572914	1.0	0.921875
32	0.0016700285232218448	0.4716922529041767	1.0	0.921875
33	0.0016184775231522508	0.48135972768068314	1.0	0.921875
34	0.0015066473242768552	0.4876873418688774	1.0	0.921875
35	0.0014337253851408605	0.4944952428340912	1.0	0.921875
36	0.0013838905560987769	0.5173822790384293	1.0	0.921875
37	0.0013786543968308251	0.5161542817950249	1.0	0.921875
38	0.0012831253334297799	0.5225359983742237	1.0	0.921875
39	0.0013373776091611944	0.5206571780145168	1.0	0.921875
40	0.0012790393993782345	0.532339558005333	1.0	0.921875
41	0.0011647835599433165	0.5349762998521328	1.0	0.921875
42	0.0010651313787093386	0.5667297802865505	1.0	0.921875
43	0.0010379461200500373	0.5414012335240841	1.0	0.921875
44	0.0009446981330256676	0.5394206270575523	1.0	0.921875
45	0.0009399215505254688	0.5376692302525043	1.0	0.921875
46	0.0009134685769822681	0.5270388573408127	1.0	0.921875
47	0.0008263501549663488	0.5202736780047417	1.0	0.921875
48	0.0009159055498457747	0.5244312509894371	1.0	0.9427083333333333
49	0.0009060948777914746	0.5269432254135609	1.0	0.9427083333333333
50	0.0007461160294042202	0.5345673151314259	1.0	0.9427083333333333

Chosen model = epoch number 8


Train data : Accu-0.99609375	Loss-0.05877781682647765
Train data report 
-              precision    recall  f1-score   support

     class 0  1.0000000 0.9952941 0.9976415       425
     class 1  0.9726027 1.0000000 0.9861111        71

    accuracy                      0.9959677       496
   macro avg  0.9863014 0.9976471 0.9918763       496
weighted avg  0.9960782 0.9959677 0.9959910       496








Valid data : Accu-0.9270833333333333	Loss-0.30202658474445343
Valid data report 
-              precision    recall  f1-score   support

     class 0  0.9583333 0.9583333 0.9583333        48
     class 1  0.7500000 0.7500000 0.7500000         8

    accuracy                      0.9285714        56
   macro avg  0.8541667 0.8541667 0.8541667        56
weighted avg  0.9285714 0.9285714 0.9285714        56








Test data : Accu-0.903125	Loss-0.8729328811168671
Test data report 
-              precision    recall  f1-score   support

     class 0  0.8947368 1.0000000 0.9444444        51
     class 1  1.0000000 0.4545455 0.6250000        11

    accuracy                      0.9032258        62
   macro avg  0.9473684 0.7272727 0.7847222        62
weighted avg  0.9134126 0.9032258 0.8877688        62





